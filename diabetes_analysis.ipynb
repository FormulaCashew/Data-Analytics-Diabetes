{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import kagglehub\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from Class_implementations import Graphics, DataProcessor, KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Data Loading ################################\n",
    "csv_name = \"diabetes_dataset.csv\"\n",
    "\n",
    "# Download dataset if it doesn't exist\n",
    "if (not os.path.exists(csv_name)):\n",
    "    path = kagglehub.dataset_download(\"mohankrishnathalla/diabetes-health-indicators-dataset\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "\n",
    "    # move dataset to local directory\n",
    "    try:\n",
    "        path = shutil.move(os.path.join(path, csv_name), \".\")\n",
    "        print(\"New path to dataset files:\", path)\n",
    "    except:\n",
    "        print(\"Error moving dataset files\")\n",
    "else:\n",
    "    print(\"Dataset already exists in current directory\")\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(csv_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Initial Data Cleaning ################################\n",
    "\n",
    "# Print the first 5 rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Calculate the number of missing values in each column\n",
    "missing_values = df.isnull().sum().sum()\n",
    "if missing_values > 0:\n",
    "    print(f\"{missing_values} missing values in the dataset\")\n",
    "    # Drop rows with missing values if necessary\n",
    "    df_dropped = df.dropna()\n",
    "else:\n",
    "    print(\"No missing values in the dataset\")\n",
    "    df_dropped = df.copy()\n",
    "\n",
    "# Remove diabetes risk column as it may be a target variable\n",
    "df_dropped = df_dropped.drop(\"diabetes_risk_score\", axis=1)\n",
    "print(\"Cleaned dataframe:\", df_dropped.head())\n",
    "\n",
    "# Count the number of rows and columns\n",
    "print(\"Dataframe shape:\", df_dropped.shape)\n",
    "\n",
    "# Get numerical columns\n",
    "num_columns = df_dropped.select_dtypes(include=[np.number]).columns\n",
    "print(\"Numerical columns:\", num_columns)\n",
    "\n",
    "# Get categorical columns\n",
    "cat_columns = df_dropped.select_dtypes(include= 'object').columns\n",
    "print(\"Categorical columns:\", cat_columns)\n",
    "\n",
    "# Print unique values for non numerical columns\n",
    "for col in df_dropped.columns:\n",
    "    if df_dropped[col].dtype == 'object': # Categorical columns\n",
    "        print(f\"Unique values for {col}: {df_dropped[col].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ EDA Visualization #################################\n",
    "\n",
    "# Create DataProcessor object from cleaned columns\n",
    "processor = DataProcessor(df_dropped)\n",
    "\n",
    "# Remove outliers from numerical columns which are not binary\n",
    "cols_outlier_check = [\"age\", \"alcohol_consumption_per_week\", \"physical_activity_minutes_per_week\", \"diet_score\", \"sleep_hours_per_day\", \"screen_time_hours_per_day\", \"hypertension_history\", \"cardiovascular_history\", \"bmi\", \"waist_to_hip_ratio\", \"systolic_bp\", \"diastolic_bp\", \"heart_rate\", \"cholesterol_total\", \"hdl_cholesterol\", \"ldl_cholesterol\", \"triglycerides\", \"glucose_fasting\", \"glucose_postprandial\", \"insulin_level\", \"hba1c\"]\n",
    "processor.remove_outliers(cols_outlier_check, threshold=2.0)\n",
    "df_dropped = processor.get_data() # Update dataframe using a copy\n",
    "print(\"Dataframe shape after removing outliers:\", df_dropped.shape)\n",
    "\n",
    "# Subsample data\n",
    "df_subsampled = processor.subsample_data(fraction=0.1)\n",
    "graphics = Graphics(df_subsampled)\n",
    "\n",
    "# Show correlation matrix\n",
    "if False:\n",
    "    graphics_total = Graphics(df_dropped) # Important to use the total dataset to show correlation matrix\n",
    "    graphics_total.show_correlation_matrix(num_columns)\n",
    "\n",
    "# Based on correlation matrix above, select important numerical attributes with correlation > 0.1, ordered by correlation\n",
    "important_attributes = [\"hba1c\", \"glucose_postprandial\", \"glucose_fasting\", \"family_history_diabetes\", \"age\", \"bmi\", \"systolic_bp\"]\n",
    "important_attributes_w_target = important_attributes + [\"diagnosed_diabetes\"]\n",
    "\n",
    "important_columns = df_subsampled[important_attributes].columns\n",
    "important_columns_w_target = df_subsampled[important_attributes_w_target].columns\n",
    "\n",
    "# See distribution of important attributes\n",
    "graphics.show_histograms(important_columns)\n",
    "# Confirm correlation matrix values\n",
    "graphics.show_correlation_matrix(important_columns_w_target)\n",
    "\n",
    "# Show scatter matrix\n",
    "if True:\n",
    "    graphics.show_scatter_matrix(important_columns_w_target)\n",
    "\n",
    "# Show boxplots to check for outliers\n",
    "if True:\n",
    "    graphics.show_boxplots(important_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Normalization ################################\n",
    "\n",
    "# Normalize numerical data\n",
    "processor = DataProcessor(df_dropped)\n",
    "cols_to_norm = df_dropped.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if \"diagnosed_diabetes\" in cols_to_norm:\n",
    "    cols_to_norm.remove(\"diagnosed_diabetes\")\n",
    "norm_df = processor.normalize_data(cols_to_norm)\n",
    "\n",
    "# Check if done successfully\n",
    "print(norm_df['age'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Encoding #####################################\n",
    "\n",
    "# Drop rows with gender = Other as it not an useful feature\n",
    "norm_df = norm_df[norm_df['gender'] != 'Other']\n",
    "\n",
    "# Convert object columns to numeric codes\n",
    "# Encoding guide:\n",
    "# Gender: Male = 0, Female = 1\n",
    "# Ethnicity: Asian = 0, White = 1, Hispanic = 2, Black = 3, Other = 4\n",
    "# Education level: Highschool = 0, Graduate = 1, Postgraduate = 2, No formal = 3\n",
    "# Income level: Lower-Middle = 0, Middle = 1, Low = 2, Upper-Middle = 3, High = 4\n",
    "# Employment status: Employed = 0, Unemployed = 1, Retired = 2, Student = 3\n",
    "# Smoking status: Never = 0, Former = 1, Current = 2\n",
    "# Diabetes stage: Type 2 = 0, No Diabetes = 1, Pre-Diabetes = 2, Gestational = 3, Type 1 = 4\n",
    "encoded_df = norm_df.copy()\n",
    "for col in norm_df.columns:\n",
    "    if norm_df[col].dtype == 'object':\n",
    "        encoded_df[col] = norm_df[col].astype('category').cat.codes\n",
    "\n",
    "# Print dtypes to check if encoding was successful\n",
    "print(encoded_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ EDA Visualization Part 2 ################################\n",
    "\n",
    "# Update classes\n",
    "processor = DataProcessor(encoded_df)\n",
    "graphics = Graphics(encoded_df) # Update Graphics object with encoded data\n",
    "\n",
    "# check for correlation matrix values now for categorical data\n",
    "cols_to_check = cat_columns.tolist() + ['diagnosed_diabetes']\n",
    "print(\"cols_to_check:\", cols_to_check)\n",
    "graphics.show_correlation_matrix(cols_to_check)\n",
    "# After encoding, correlation matrix values show little correlation with target variable\n",
    "\n",
    "graphics.compare_hist(\"glucose_fasting\", \"glucose_postprandial\")\n",
    "################# Histograms #################\n",
    "# Histogram of education level vs diagnosed_diabetes\n",
    "graphics.show_hist_axis(\"education_level\", \"diagnosed_diabetes\")\n",
    "# It shows that lower education level has higher count of diagnosed diabetes\n",
    "\n",
    "# Histogram of income level vs diagnosed_diabetes\n",
    "graphics.show_hist_axis(\"income_level\", \"diagnosed_diabetes\")\n",
    "# Shows that higher income level has higher count of diagnosed diabetes, but may be due to having the chance to be diagnosed\n",
    "\n",
    "# Histogram of employment status vs diagnosed_diabetes\n",
    "graphics.show_hist_axis(\"employment_status\", \"diagnosed_diabetes\")\n",
    "# Shows that employed has higher count of diagnosed diabetes\n",
    "\n",
    "# Histogram of smoking status vs diagnosed_diabetes\n",
    "graphics.show_hist_axis(\"smoking_status\", \"diagnosed_diabetes\")\n",
    "# Shows that current smoking has higher count of diagnosed diabetes\n",
    "\n",
    "important_attributes = [\"hba1c\", \"glucose_postprandial\", \"glucose_fasting\", \"family_history_diabetes\", \"age\", \"bmi\", \"systolic_bp\", \"smoking_status\", \"employment_status\", \"education_level\", \"income_level\"]\n",
    "important_attributes_w_target = important_attributes + [\"diagnosed_diabetes\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# KMeans Clustering #################\n",
    "# Update objects from class with cleaned columns\n",
    "df_subsampled_num_encoded = processor.subsample_data(fraction=0.1)\n",
    "data_processor = DataProcessor(df_subsampled_num_encoded)\n",
    "\n",
    "# Show kmeans clustering\n",
    "# Using hba1c and glucose fasting as they have the highest correlation with target variable\n",
    "data_processor.plot_kmeans_clustering([\"hba1c\",\"glucose_fasting\"], n_clusters=2)\n",
    "# Now test for hba1c and glucose_postprandial\n",
    "data_processor.plot_kmeans_clustering([\"hba1c\",\"glucose_postprandial\"], n_clusters=2)\n",
    "# Now test for glucose fasting and glucose_postprandial\n",
    "data_processor.plot_kmeans_clustering([\"glucose_fasting\",\"glucose_postprandial\"], n_clusters=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### Modeling #########################################\n",
    "\n",
    "# IMPORTANT: Use 5% to 10% of the dataset for training and testing, knn is heavy and takes a lot of time to run\n",
    "subsampled_df = processor.subsample_data(fraction=0.05)\n",
    "subsampled_processor = DataProcessor(subsampled_df)\n",
    "train_df, test_df = subsampled_processor.train_test_split(test_size=0.2)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Decision Tree Library #################\n",
    "\n",
    "if True:\n",
    "    # Create Decision Tree object\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(train_df[important_attributes], train_df['diagnosed_diabetes'])\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = decision_tree.predict(test_df[important_attributes])\n",
    "    # Calculate accuracy\n",
    "    correct = sum(predictions == test_df['diagnosed_diabetes'])\n",
    "    print(f\"Accuracy for Decision Tree: {correct/len(test_df)}\")\n",
    "    decision_tree_accuracy = correct/len(test_df)\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(test_df['diagnosed_diabetes'], predictions)\n",
    "    sns.heatmap(cm, annot=True)\n",
    "    plt.title(\"Confusion Matrix Decision Tree\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# KNN Library #################\n",
    "\n",
    "if True:\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(train_df[important_attributes], train_df['diagnosed_diabetes'])\n",
    "    # Make predictions\n",
    "    predictions = knn.predict(test_df[important_attributes])\n",
    "    # Calculate accuracy\n",
    "    correct = sum(predictions == test_df['diagnosed_diabetes'])\n",
    "    print(f\"Accuracy for KNN: {correct/len(test_df)}\")\n",
    "    knn_accuracy = correct/len(test_df)\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(test_df['diagnosed_diabetes'], predictions)\n",
    "    sns.heatmap(cm, annot=True)\n",
    "    plt.title(\"Confusion Matrix KNN Library\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# KNN Personal #################\n",
    "if False:\n",
    "    # This code has been disabled as it takes a lot of time to run\n",
    "    # During testing, it was found to give the same results as the library implementation\n",
    "    # It is left here for reference, but the library implementation is preferred due to its speed\n",
    "    # Create KNN object\n",
    "    knn = KNN(k=3)\n",
    "    knn.store(train_df[important_attributes], train_df['diagnosed_diabetes'])\n",
    "    # Make predictions\n",
    "    predictions = knn.predict(test_df[important_attributes])\n",
    "    # Calculate accuracy\n",
    "    correct = sum(predictions == test_df['diagnosed_diabetes'])\n",
    "    print(f\"Accuracy: {correct/len(test_df)}\")\n",
    "    # Plot confusion matrix\n",
    "    knn.plot_confusion_matrix(test_df[important_attributes], test_df['diagnosed_diabetes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Random Forest #################\n",
    "if True:\n",
    "    random_forest = RandomForestClassifier(n_estimators=100)\n",
    "    random_forest.fit(train_df[important_attributes], train_df['diagnosed_diabetes'])\n",
    "    # Make predictions\n",
    "    predictions = random_forest.predict(test_df[important_attributes])\n",
    "    # Calculate accuracy\n",
    "    correct = sum(predictions == test_df['diagnosed_diabetes'])\n",
    "    print(f\"Accuracy for Random Forest: {correct/len(test_df)}\")\n",
    "    random_forest_accuracy = correct/len(test_df)\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(test_df['diagnosed_diabetes'], predictions)\n",
    "    sns.heatmap(cm, annot=True)\n",
    "    plt.title(\"Confusion Matrix Random Forest\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    print(cm)\n",
    "\n",
    "    # Plot feature importance\n",
    "    feature_importance = random_forest.feature_importances_\n",
    "    feature_names = train_df[important_attributes].columns\n",
    "    feature_importance = pd.Series(feature_importance, index=feature_names)\n",
    "    feature_importance.sort_values(ascending=False, inplace=True)\n",
    "    feature_importance.plot(kind='bar')\n",
    "    plt.title(\"Feature Importance Random Forest\")\n",
    "    plt.show()\n",
    "    # Shows a bar chart a bit different than the one from decision tree\n",
    "    # Glucose postprandial has a higher importance but hba1c is still the most important\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Gaussian NB ######################\n",
    "\n",
    "if True:\n",
    "    gaussian_nb = GaussianNB()\n",
    "    gaussian_nb.fit(train_df[important_attributes], train_df['diagnosed_diabetes'])\n",
    "    # Make predictions\n",
    "    predictions = gaussian_nb.predict(test_df[important_attributes])\n",
    "    # Calculate accuracy\n",
    "    correct = sum(predictions == test_df['diagnosed_diabetes'])\n",
    "    print(f\"Accuracy for Gaussian NB: {correct/len(test_df)}\")\n",
    "    gaussian_nb_accuracy = correct/len(test_df)\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(test_df['diagnosed_diabetes'], predictions)\n",
    "    sns.heatmap(cm, annot=True)\n",
    "    plt.title(\"Confusion Matrix Gaussian NB\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### XG Boost ####################\n",
    "\n",
    "if True:\n",
    "    xgboost = XGBClassifier()\n",
    "    xgboost.fit(train_df[important_attributes], train_df['diagnosed_diabetes'])\n",
    "    # Make predictions\n",
    "    predictions = xgboost.predict(test_df[important_attributes])\n",
    "    # Calculate accuracy\n",
    "    correct = sum(predictions == test_df['diagnosed_diabetes'])\n",
    "    print(f\"Accuracy for XG Boost: {correct/len(test_df)}\")\n",
    "    xgboost_accuracy = correct/len(test_df)\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(test_df['diagnosed_diabetes'], predictions)\n",
    "    sns.heatmap(cm, annot=True)\n",
    "    plt.title(\"Confusion Matrix XG Boost\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Model Comparison #################\n",
    "print(f\"Decision Tree Accuracy: {decision_tree_accuracy}\")\n",
    "print(f\"KNN Accuracy: {knn_accuracy}\")\n",
    "print(f\"Random Forest Accuracy: {random_forest_accuracy}\")\n",
    "print(f\"Gaussian NB Accuracy: {gaussian_nb_accuracy}\")\n",
    "print(f\"XG Boost Accuracy: {xgboost_accuracy}\")\n",
    "best_model = max(decision_tree_accuracy, knn_accuracy, random_forest_accuracy, gaussian_nb_accuracy)\n",
    "\n",
    "\n",
    "if best_model == decision_tree_accuracy:\n",
    "    best_model_name = \"Decision Tree\"\n",
    "elif best_model == knn_accuracy:\n",
    "    best_model_name = \"KNN\"\n",
    "elif best_model == random_forest_accuracy:\n",
    "    best_model_name = \"Random Forest\"\n",
    "elif best_model == gaussian_nb_accuracy:\n",
    "    best_model_name = \"Gaussian NB\"\n",
    "elif best_model == xgboost_accuracy:\n",
    "    best_model_name = \"XG Boost\"\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"{best_model_name} Accuracy: {best_model}\")\n",
    "with open(\"model_best.txt\", \"w\") as f:\n",
    "    f.write(best_model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}